import os
import sys
import shutil
import glob

# KÃ¼tÃ¼phane yollarÄ±nÄ± garantiye al
sys.path.append(os.getcwd())

from langchain_community.document_loaders import CSVLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma

# --- AYARLAR ---
DATA_KLASORU = "data"           # CSV'lerin olduÄŸu klasÃ¶r
VECTOR_DB_KLASORU = "chroma_db" # VeritabanÄ±nÄ±n kaydedileceÄŸi yer

def create_pipeline():
    print("--- YAPAY ZEKA MÃœHENDÄ°SLÄ°ÄÄ° VERÄ° YÃœKLEME MODU ---")
    
    # 1. TEMÄ°ZLÄ°K: Eski 'ktun rag' verilerini temizleyelim
    if os.path.exists(VECTOR_DB_KLASORU):
        print(f"ğŸ§¹ Eski veritabanÄ± tespit edildi ve siliniyor (Temiz Kurulum)...")
        try:
            shutil.rmtree(VECTOR_DB_KLASORU)
            print("   -> Temizlik baÅŸarÄ±lÄ±.")
        except Exception as e:
            print(f"   âš ï¸ HATA: KlasÃ¶r silinemedi. Chatbot veya terminal aÃ§Ä±k olabilir mi? ({e})")
            return

    # 2. DOSYALARI BUL
    csv_yollari = glob.glob(os.path.join(DATA_KLASORU, "*.csv"))
    
    if not csv_yollari:
        print(f"âŒ HATA: '{DATA_KLASORU}' klasÃ¶rÃ¼nde hiÃ§ CSV dosyasÄ± yok!")
        return

    print(f"ğŸ“‚ Ä°ÅŸlenecek Dosya SayÄ±sÄ±: {len(csv_yollari)}")
    
    tum_dokumanlar = []
    
    # 3. YÃœKLEME DÃ–NGÃœSÃœ
    for dosya in csv_yollari:
        dosya_adi = os.path.basename(dosya)
        print(f"   Reading -> {dosya_adi} ... ", end="")
        
        try:
            # DÄ°KKAT: Senin yeni dosyalarÄ±nda link sÃ¼tunu "KAYNAK LÄ°NK" olarak geÃ§iyor.
            # CSVLoader, diÄŸer tÃ¼m sÃ¼tunlarÄ± (Tarih, BaÅŸlÄ±k, Ä°Ã§erik) otomatik olarak metne ekler.
            loader = CSVLoader(
                file_path=dosya, 
                encoding="utf-8", 
                source_column="KAYNAK LÄ°NK" 
            )
            veri = loader.load()
            tum_dokumanlar.extend(veri)
            print(f"âœ… (Eklenen belge: {len(veri)})")
        except Exception as e:
            print(f"\n   âŒ HATA: Dosya okunamadÄ±. 'KAYNAK LÄ°NK' sÃ¼tunu var mÄ±? Hata: {e}")

    print(f"\nğŸ“Š Toplam Veri Havuzu: {len(tum_dokumanlar)} parÃ§a")

    if len(tum_dokumanlar) == 0:
        print("YÃ¼klenecek veri bulunamadÄ±.")
        return

    # 4. PARÃ‡ALAMA (CHUNKING)
    # Ders programlarÄ± ve tablolar olduÄŸu iÃ§in chunk size'Ä± biraz geniÅŸ tutuyoruz
    print("âœ‚ï¸  Metinler optimize ediliyor...")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1200, chunk_overlap=200)
    splits = text_splitter.split_documents(tum_dokumanlar)
    
    # 5. EMBEDDING VE KAYIT
    print(f"ğŸ§  Yapay Zeka Modeli (MiniLM) Ã§alÄ±ÅŸÄ±yor... VeritabanÄ± oluÅŸturuluyor...")
    embedding_model = HuggingFaceEmbeddings(
        model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    )

    vectorstore = Chroma.from_documents(
        documents=splits,
        embedding=embedding_model,
        persist_directory=VECTOR_DB_KLASORU
    )
    
    print(f"\nğŸ‰ SÄ°STEM HAZIR! TÃ¼m yapay zeka mÃ¼hendisliÄŸi verileri yÃ¼klendi.")

if __name__ == "__main__":
    create_pipeline()